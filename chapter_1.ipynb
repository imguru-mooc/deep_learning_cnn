{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 합성곱 신경망 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([2, 8, 3, 7, 1, 2, 0, 4, 5])\n",
    "w = np.array([2, 1, 5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flip() 함수를 이용한 배열 뒤집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r = np.flip(w)\n",
    "print(w_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이의 점 곱으로 합성곱 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(np.dot(x[i:i+4], w_r.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "싸이파이로 합성곱 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "convolve(x, w, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "싸이파이로 교차상관 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "correlate(x, w, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate(x, w, mode='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세임 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate(x, w, mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원 배열에서 합성곱 수행 ( mode='valid' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "w = np.array([[2, 0], [0, 0]])\n",
    "from scipy.signal import correlate2d\n",
    "correlate2d(x, w, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원 배열에서 합성곱 수행 ( mode='same' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate2d(x, w, mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스의 Conv2D를 이용한 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 초기화(4차원 배열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "image = tf.constant([[[[1],[2],[3]],\n",
    "                      [[4],[5],[6]],\n",
    "                      [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.numpy().reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D를 이용한 합성곱(세임 패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "print(conv2d.numpy().reshape(3,3))\n",
    "plt.imshow(conv2d.numpy().reshape(3,3), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D를 이용한 합성곱(벨리드 패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "print(conv2d.numpy().reshape(2,2))\n",
    "plt.imshow(conv2d.numpy().reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필터가 3개인 경우 합성곱 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],[[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=3, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    print(feature_map.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지의 채널이 3개인 경우( weight도 채널이 3개임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "image = tf.constant([[[[1,1,1],[2,2,2],[3,3,3]],\n",
    "                      [[4,4,4],[5,5,5],[6,6,6]],\n",
    "                      [[7,7,7],[8,8,8],[9,9,9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "weight = np.array([[[[1],[2],[3]],[[1],[2],[3]]],[[[1],[2],[3]],[[1],[2],[3]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "print(conv2d)\n",
    "# feature_maps = np.swapaxes(conv2d, 0, 3)\n",
    "# for i, feature_map in enumerate(feature_maps):\n",
    "#     print(feature_map.reshape(3,3))\n",
    "#     plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림이 5x5 이고 채널이 3개인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.constant(  [[ \n",
    "                         [[1,0,1],[1,1,1],[1,1,1],[0,0,1],[0,1,0]], \n",
    "                         [[0,0,1],[1,1,1],[1,1,1],[1,1,1],[0,0,0]], \n",
    "                         [[0,0,0],[0,0,0],[1,1,0],[1,1,1],[1,0,1]], \n",
    "                         [[0,0,0],[0,0,1],[1,1,1],[1,1,1],[0,1,0]], \n",
    "                         [[0,1,0],[1,1,1],[1,1,1],[0,0,0],[0,0,0]] \n",
    "                      ]],     dtype=np.float32)\n",
    "\n",
    "maps = np.swapaxes(image, 0, 3)\n",
    "for i, map in enumerate(maps):\n",
    "    print(map.reshape(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight 3x3 이고 이미지가 채널 3이므로 weight도 채널 3개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.array( [ \n",
    "                     [[[1],[0],[-1]], [[0],[-1],[0]], [[1],[0],[0]]],\n",
    "                     [[[0],[-1],[0]], [[1],[1],[1]], [[0],[-1],[0]]],\n",
    "                     [[[1],[1],[0]], [[0],[-1],[0]], [[1],[0],[-1]]]\n",
    "                   ] )\n",
    "# maps = np.swapaxes(weight, 1, 2)\n",
    "# maps = np.swapaxes(maps, 0, 1)\n",
    "\n",
    "maps = np.transpose(weight,(2,0,1,3))\n",
    "for i, map in enumerate(maps):\n",
    "    print(map.reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산(벨리드 패딩 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='valid', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    print(feature_map.reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필터가 2개이고 채널이 3인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "swapaxes를 이용한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.array( [ \n",
    "                     [[[1,1],[0,1],[-1,-1]], [[0,0],[-1,0],[0,0]], [[1,1],[0,1],[0,0]]],\n",
    "                     [[[0,0],[-1,0],[0,0]], [[1,1],[1,1],[1,1]], [[0,0],[-1,0],[0,0]]],\n",
    "                     [[[1,1],[1,1],[0,0]], [[0,0],[-1,0],[0,0]], [[1,1],[0,1],[-1,-1]]]\n",
    "                   ] )\n",
    "maps = np.swapaxes(weight, 1, 2)\n",
    "maps = np.swapaxes(maps, 0, 1)\n",
    "\n",
    "for map in maps:\n",
    "    map = np.swapaxes(map, 1, 2)\n",
    "    map = np.swapaxes(map, 0, 1)\n",
    "    for filter in map:\n",
    "       print(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transpose를 이용한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3,3,3,2) => (3,2,3,3)\n",
    "weight = np.array( [ \n",
    "                     [[[1,1],[0,1],[-1,-1]], [[0,0],[-1,0],[0,0]], [[1,1],[0,1],[0,0]]],\n",
    "                     [[[0,0],[-1,0],[0,0]], [[1,1],[1,1],[1,1]], [[0,0],[-1,0],[0,0]]],\n",
    "                     [[[1,1],[1,1],[0,0]], [[0,0],[-1,0],[0,0]], [[1,1],[0,1],[-1,-1]]]\n",
    "                   ] )\n",
    "\n",
    "maps = np.transpose(weight, (2,3,0,1) )\n",
    "\n",
    "for map in maps:\n",
    "    for filter in map:\n",
    "       print(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산( 필터 2개, 채널 3개, 벨리드 패딩 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init = tf.constant_initializer(weight)\n",
    "conv2d = tf.keras.layers.Conv2D(filters=2, kernel_size=3, padding='valid', kernel_initializer=weight_init)(image)\n",
    "print(\"conv2d.shape\", conv2d.shape)  # ( 1,3,3,2)\n",
    "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
    "for feature_map in feature_maps:\n",
    "    print(feature_map.reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 배열 축교환 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(3,2,2)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "b = np.swapaxes(a, 0, 1)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(3,2,2)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "b = np.swapaxes(a, 1, 2)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(3,2,2)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "b = np.swapaxes(a, 0, 2)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4차원 배열 축교환 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16).reshape(2,2,2,2)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "b = np.swapaxes(a, 0, 3)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀링 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strides=1, padding='valid' 인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.constant([[[[4],[3]],[[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='valid')(image)\n",
    "print(image.shape)\n",
    "print(pool.shape)\n",
    "print(pool.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strides=1, padding='same' 인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.constant([[[[4],[3]],[[2],[1]]]], dtype=np.float32)\n",
    "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='same')(image)\n",
    "print(pool.shape)\n",
    "print(pool.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.mnist\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.astype(np.float32) / 255.\n",
    "test_images = test_images.astype(np.float32) / 255.\n",
    "\n",
    "img = train_images[0]\n",
    "plt.imshow( img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(-1,28,28,1)\n",
    "img = tf.convert_to_tensor(img)\n",
    "\n",
    "print(\"weight.shape\", weight.shape)\n",
    "weight_init = keras.initializers.RandomNormal(stddev=0.01)\n",
    "conv2d = keras.layers.Conv2D(filters=5, kernel_size=3, padding='same', \n",
    "                             strides=(2,2), kernel_initializer=weight_init)(img)\n",
    "print(\"conv2d.shape\", conv2d.shape)\n",
    "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(14,14), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맥스 풀링 연산 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(conv2d)\n",
    "print(pool.shape)\n",
    "feature_maps = np.swapaxes(pool, 0, 3)\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(7,7), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zs = np.arange(-10., 10., 0.1)\n",
    "gs = [1/(1+np.exp(-z)) for z in zs]\n",
    "plt.plot(zs, gs)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('1/(1+e^-z)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 미분 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "zs = np.arange(-10., 10., 0.1)\n",
    "gs = [ sigmoid(z)*(1-sigmoid(z)) for z in zs]\n",
    "plt.plot(zs, gs)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('sigmoid() derivative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 볼릭 탄젠트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = np.arange(-10., 10., 0.1)\n",
    "gs = [ np.tanh(z) for z in zs]\n",
    "plt.plot(zs, gs)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('tanh()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 볼릭 탄젠트 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = np.arange(-10., 10., 0.1)\n",
    "gs = [ (1-np.tanh(z))*(1+np.tanh(z)) for z in zs]\n",
    "plt.plot(zs, gs)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('tanh() deivative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "렐루 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 2, -3, 4, -5])\n",
    "relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = np.arange(-10., 10., 0.1)\n",
    "gs = [ relu(z) for z in zs]\n",
    "plt.plot(zs, gs)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('relu()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_out = tf.nn.relu(x)\n",
    "r_out.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 합성곱 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ConvolutionNetwork:\n",
    "    \n",
    "    def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
    "        self.n_kernels = n_kernels  # 합성곱의 커널 개수\n",
    "        self.kernel_size = 3        # 커널 크기\n",
    "        self.optimizer = None       # 옵티마이저\n",
    "        self.conv_w = None          # 합성곱 층의 가중치\n",
    "        self.conv_b = None          # 합성곱 층의 절편\n",
    "        self.units = units          # 은닉층의 뉴런 개수\n",
    "        self.batch_size = batch_size  # 배치 크기\n",
    "        self.w1 = None              # 은닉층의 가중치\n",
    "        self.b1 = None              # 은닉층의 절편\n",
    "        self.w2 = None              # 출력층의 가중치\n",
    "        self.b2 = None              # 출력층의 절편\n",
    "        self.a1 = None              # 은닉층의 활성화 출력\n",
    "        self.losses = []            # 훈련 손실\n",
    "        self.val_losses = []        # 검증 손실\n",
    "        self.lr = learning_rate     # 학습률\n",
    "\n",
    "    def forpass(self, x):\n",
    "        # 3x3 합성곱 연산을 수행합니다.\n",
    "#         print('x.shape',x.shape)\n",
    "#         print('self.conv_w.shape',self.conv_w.shape)\n",
    "#         print('self.conv_w',self.conv_w)\n",
    "        c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
    "        # 렐루 활성화 함수를 적용합니다.\n",
    "#         print('c_out.shape',c_out.shape)\n",
    "#         print('c_out',c_out)\n",
    "        r_out = tf.nn.relu(c_out)\n",
    "#         print('r_out.shape',r_out.shape)\n",
    "#         print('r_out',r_out)\n",
    "        # 2x2 최대 풀링을 적용합니다.\n",
    "        p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
    "        # 첫 번째 배치 차원을 제외하고 출력을 일렬로 펼칩니다.\n",
    "#         print('p_out.shape',p_out.shape)\n",
    "#         print('p_out',p_out)\n",
    "        f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
    "#         print('f_out.shape',f_out.shape)\n",
    "        z1 = tf.matmul(f_out, self.w1) + self.b1     # 첫 번째 층의 선형 식을 계산합니다\n",
    "        a1 = tf.nn.relu(z1)                          # 활성화 함수를 적용합니다\n",
    "        z2 = tf.matmul(a1, self.w2) + self.b2        # 두 번째 층의 선형 식을 계산합니다.\n",
    "        return z2\n",
    "    \n",
    "    def init_weights(self, input_shape, n_classes):\n",
    "        g = tf.initializers.glorot_uniform()\n",
    "        self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
    "        self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
    "        n_features = 14 * 14 * self.n_kernels\n",
    "        self.w1 = tf.Variable(g((n_features, self.units)))          # (특성 개수, 은닉층의 크기)\n",
    "        self.b1 = tf.Variable(np.zeros(self.units), dtype=float)    # 은닉층의 크기\n",
    "        self.w2 = tf.Variable(g((self.units, n_classes)))           # (은닉층의 크기, 클래스 개수)\n",
    "        self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)     # 클래스 개수\n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        self.init_weights(x.shape, y.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
    "        # epochs만큼 반복합니다.\n",
    "        for i in range(epochs):\n",
    "            print('에포크', i, end=' ')\n",
    "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\n",
    "                print('.', end='')\n",
    "                self.training(x_batch, y_batch)\n",
    "                # 배치 손실을 기록합니다.\n",
    "                batch_losses.append(self.get_loss(x_batch, y_batch))\n",
    " \n",
    "            print()\n",
    "            # 배치 손실 평균내어 훈련 손실 값으로 저장합니다.\n",
    "            self.losses.append(np.mean(batch_losses))\n",
    "            # 검증 세트에 대한 손실을 계산합니다.\n",
    "            self.val_losses.append(self.get_loss(x_val, y_val))\n",
    "\n",
    "    # 미니배치 제너레이터 함수\n",
    "    def gen_batch(self, x, y):\n",
    "        bins = len(x) // self.batch_size                   # 미니배치 횟수\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size * i\n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
    "            \n",
    "    def training(self, x, y):\n",
    "        m = len(x)                    # 샘플 개수를 저장합니다.\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
    "            # 손실을 계산합니다.\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        weights_list = [self.conv_w, self.conv_b,\n",
    "                        self.w1, self.b1, self.w2, self.b2]\n",
    "        # 가중치에 대한 그래디언트를 계산합니다.\n",
    "        grads = tape.gradient(loss, weights_list)\n",
    "        # 가중치를 업데이트합니다.\n",
    "        self.optimizer.apply_gradients(zip(grads, weights_list))\n",
    "   \n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)                 # 정방향 계산을 수행합니다.\n",
    "        return np.argmax(z.numpy(), axis=1) # 가장 큰 값의 인덱스를 반환합니다.\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
    "\n",
    "    def get_loss(self, x, y):\n",
    "        z = self.forpass(x)                 # 정방향 계산을 수행합니다.\n",
    "        # 손실을 계산하여 저장합니다.\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
    "        return loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동 미분의 사용 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x ** 3 + 2 * x + 5\n",
    "\n",
    "# 그래디언트를 계산합니댜.\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fashion mnist 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, \n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train 형상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과값 원-핫 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_train_encoded[0])\n",
    "print(y_train_encoded.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 4차원 형상으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터 표준화 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_val = x_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\n",
    "cn.fit(x_train, y_train_encoded, \n",
    "       x_val=x_val, y_val=y_val_encoded, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련, 검증 손실 그래프 그리고 검증 세트의 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cn.losses)\n",
    "plt.plot(cn.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn.score(x_val, y_val_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 케라스로 합성곱 신경망 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 클래스들을 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱층 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.keras.Sequential()\n",
    "conv1.add(Conv2D(10, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링층 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.add(MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전 연결층에 주입할 수 있도록 특성 맵 펼치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전 연결층 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.add(Dense(100, activation='relu'))\n",
    "conv1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = conv1.fit(x_train, y_train_encoded, epochs=20, \n",
    "                    validation_data=(x_val, y_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 그래프와 정확도 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃 적용해 합성곱 신경망 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스로 만든 합성곱 신경망에 드롭아웃 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "conv2 = tf.keras.Sequential()\n",
    "conv2.add(Conv2D(10, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "conv2.add(MaxPooling2D((2, 2)))\n",
    "conv2.add(Flatten())\n",
    "conv2.add(Dropout(0.5))\n",
    "conv2.add(Dense(100, activation='relu'))\n",
    "conv2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드롭아웃층 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = conv2.fit(x_train, y_train_encoded, epochs=20, \n",
    "                    validation_data=(x_val, y_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 그래프와 정확도 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
